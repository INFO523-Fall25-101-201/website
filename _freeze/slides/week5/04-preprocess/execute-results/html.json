{
  "hash": "c8b455dec455710f4a20866738285b69",
  "result": {
    "markdown": "---\ntitle: Data Preprocessing\nsubtitle: Lecture 4\ntitle-slide-attributes:\n  data-background-image: ../minedata-bg.png\n  data-background-size: 600px, cover\n  data-slide-number: none\nformat: revealjs\nauto-stretch: false\n---\n\n# Warm up\n\n## Announcements\n\n-   HW 01 is due tonight, 11:59pm\n\n-   RQ #2 is due Feb 07, 11:59pm\n\n-   Project 01 peer-review is Feb 07, first round proposals are due before class\n\n## Setup\n\n::: {#setup .cell execution_count=1}\n``` {.python .cell-code}\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nimport statsmodels.api as sm\nimport scipy.stats as stats\nfrom scipy.stats import gaussian_kde\nfrom scipy.signal import find_peaks, argrelextrema\nfrom scipy.stats import pearsonr\n\n\n# Increase font size of all Seaborn plot elements\nsns.set(font_scale = 1.25)\n\n# Set Seaborn theme\nsns.set_theme(style = \"whitegrid\")\n```\n:::\n\n\n## Data Preprocessing\n\n> **Data preprocessing** can refer to manipulation, filtration or augmentation of data before it is analyzed, and is often an important step in the [data mining](https://en.wikipedia.org/wiki/Data_mining \"Data mining\") process.\n\n## Datasets {.smaller}\n\n\n\n::: columns\n::: {.column width=\"50%\"}\n**Human Freedom Index**\n\nThe Human Freedom Index is a report that attempts to summarize the idea of \"freedom\" through variables for many countries around the globe.\n\n::: {.cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-4-output-1.png){width=692 height=307}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n**Environmental Sustainability**\n\nCountries are given an overall sustainability score as well as scores in each of several different environmental areas.\n\n::: {.cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-5-output-1.png){width=700 height=307}\n:::\n:::\n\n\n:::\n:::\n\n## Question\n\nHow does **environmental stability** [correlate]{.underline} with **human freedom indices** in [different countries]{.underline}, and what [trends]{.underline} can be observed over [recent years]{.underline}?\n\n## Dataset #1: Human Freedom Index {.smaller}\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nhfi = pd.read_csv(\"data/hfi.csv\")\nhfi.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>ISO_code</th>\n      <th>countries</th>\n      <th>region</th>\n      <th>pf_rol_procedural</th>\n      <th>pf_rol_civil</th>\n      <th>pf_rol_criminal</th>\n      <th>pf_rol</th>\n      <th>pf_ss_homicide</th>\n      <th>pf_ss_disappearances_disap</th>\n      <th>...</th>\n      <th>ef_regulation_business_bribes</th>\n      <th>ef_regulation_business_licensing</th>\n      <th>ef_regulation_business_compliance</th>\n      <th>ef_regulation_business</th>\n      <th>ef_regulation</th>\n      <th>ef_score</th>\n      <th>ef_rank</th>\n      <th>hf_score</th>\n      <th>hf_rank</th>\n      <th>hf_quartile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016</td>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>Eastern Europe</td>\n      <td>6.661503</td>\n      <td>4.547244</td>\n      <td>4.666508</td>\n      <td>5.291752</td>\n      <td>8.920429</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>4.050196</td>\n      <td>7.324582</td>\n      <td>7.074366</td>\n      <td>6.705863</td>\n      <td>6.906901</td>\n      <td>7.54</td>\n      <td>34.0</td>\n      <td>7.568140</td>\n      <td>48.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016</td>\n      <td>DZA</td>\n      <td>Algeria</td>\n      <td>Middle East &amp; North Africa</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.819566</td>\n      <td>9.456254</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>3.765515</td>\n      <td>8.523503</td>\n      <td>7.029528</td>\n      <td>5.676956</td>\n      <td>5.268992</td>\n      <td>4.99</td>\n      <td>159.0</td>\n      <td>5.135886</td>\n      <td>155.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016</td>\n      <td>AGO</td>\n      <td>Angola</td>\n      <td>Sub-Saharan Africa</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.451814</td>\n      <td>8.060260</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1.945540</td>\n      <td>8.096776</td>\n      <td>6.782923</td>\n      <td>4.930271</td>\n      <td>5.518500</td>\n      <td>5.17</td>\n      <td>155.0</td>\n      <td>5.640662</td>\n      <td>142.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>ARG</td>\n      <td>Argentina</td>\n      <td>Latin America &amp; the Caribbean</td>\n      <td>7.098483</td>\n      <td>5.791960</td>\n      <td>4.343930</td>\n      <td>5.744791</td>\n      <td>7.622974</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>3.260044</td>\n      <td>5.253411</td>\n      <td>6.508295</td>\n      <td>5.535831</td>\n      <td>5.369019</td>\n      <td>4.84</td>\n      <td>160.0</td>\n      <td>6.469848</td>\n      <td>107.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016</td>\n      <td>ARM</td>\n      <td>Armenia</td>\n      <td>Caucasus &amp; Central Asia</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.003205</td>\n      <td>8.808750</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>4.575152</td>\n      <td>9.319612</td>\n      <td>6.491481</td>\n      <td>6.797530</td>\n      <td>7.378069</td>\n      <td>7.57</td>\n      <td>29.0</td>\n      <td>7.241402</td>\n      <td>57.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 123 columns</p>\n</div>\n```\n:::\n:::\n\n\n## Understand the data {.smaller}\n\n::: panel-tabset\n## `.info()`\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nhfi.info(verbose = True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1458 entries, 0 to 1457\nData columns (total 123 columns):\n #    Column                              Dtype  \n---   ------                              -----  \n 0    year                                int64  \n 1    ISO_code                            object \n 2    countries                           object \n 3    region                              object \n 4    pf_rol_procedural                   float64\n 5    pf_rol_civil                        float64\n 6    pf_rol_criminal                     float64\n 7    pf_rol                              float64\n 8    pf_ss_homicide                      float64\n 9    pf_ss_disappearances_disap          float64\n 10   pf_ss_disappearances_violent        float64\n 11   pf_ss_disappearances_organized      float64\n 12   pf_ss_disappearances_fatalities     float64\n 13   pf_ss_disappearances_injuries       float64\n 14   pf_ss_disappearances                float64\n 15   pf_ss_women_fgm                     float64\n 16   pf_ss_women_missing                 float64\n 17   pf_ss_women_inheritance_widows      float64\n 18   pf_ss_women_inheritance_daughters   float64\n 19   pf_ss_women_inheritance             float64\n 20   pf_ss_women                         float64\n 21   pf_ss                               float64\n 22   pf_movement_domestic                float64\n 23   pf_movement_foreign                 float64\n 24   pf_movement_women                   float64\n 25   pf_movement                         float64\n 26   pf_religion_estop_establish         float64\n 27   pf_religion_estop_operate           float64\n 28   pf_religion_estop                   float64\n 29   pf_religion_harassment              float64\n 30   pf_religion_restrictions            float64\n 31   pf_religion                         float64\n 32   pf_association_association          float64\n 33   pf_association_assembly             float64\n 34   pf_association_political_establish  float64\n 35   pf_association_political_operate    float64\n 36   pf_association_political            float64\n 37   pf_association_prof_establish       float64\n 38   pf_association_prof_operate         float64\n 39   pf_association_prof                 float64\n 40   pf_association_sport_establish      float64\n 41   pf_association_sport_operate        float64\n 42   pf_association_sport                float64\n 43   pf_association                      float64\n 44   pf_expression_killed                float64\n 45   pf_expression_jailed                float64\n 46   pf_expression_influence             float64\n 47   pf_expression_control               float64\n 48   pf_expression_cable                 float64\n 49   pf_expression_newspapers            float64\n 50   pf_expression_internet              float64\n 51   pf_expression                       float64\n 52   pf_identity_legal                   float64\n 53   pf_identity_parental_marriage       float64\n 54   pf_identity_parental_divorce        float64\n 55   pf_identity_parental                float64\n 56   pf_identity_sex_male                float64\n 57   pf_identity_sex_female              float64\n 58   pf_identity_sex                     float64\n 59   pf_identity_divorce                 float64\n 60   pf_identity                         float64\n 61   pf_score                            float64\n 62   pf_rank                             float64\n 63   ef_government_consumption           float64\n 64   ef_government_transfers             float64\n 65   ef_government_enterprises           float64\n 66   ef_government_tax_income            float64\n 67   ef_government_tax_payroll           float64\n 68   ef_government_tax                   float64\n 69   ef_government                       float64\n 70   ef_legal_judicial                   float64\n 71   ef_legal_courts                     float64\n 72   ef_legal_protection                 float64\n 73   ef_legal_military                   float64\n 74   ef_legal_integrity                  float64\n 75   ef_legal_enforcement                float64\n 76   ef_legal_restrictions               float64\n 77   ef_legal_police                     float64\n 78   ef_legal_crime                      float64\n 79   ef_legal_gender                     float64\n 80   ef_legal                            float64\n 81   ef_money_growth                     float64\n 82   ef_money_sd                         float64\n 83   ef_money_inflation                  float64\n 84   ef_money_currency                   float64\n 85   ef_money                            float64\n 86   ef_trade_tariffs_revenue            float64\n 87   ef_trade_tariffs_mean               float64\n 88   ef_trade_tariffs_sd                 float64\n 89   ef_trade_tariffs                    float64\n 90   ef_trade_regulatory_nontariff       float64\n 91   ef_trade_regulatory_compliance      float64\n 92   ef_trade_regulatory                 float64\n 93   ef_trade_black                      float64\n 94   ef_trade_movement_foreign           float64\n 95   ef_trade_movement_capital           float64\n 96   ef_trade_movement_visit             float64\n 97   ef_trade_movement                   float64\n 98   ef_trade                            float64\n 99   ef_regulation_credit_ownership      float64\n 100  ef_regulation_credit_private        float64\n 101  ef_regulation_credit_interest       float64\n 102  ef_regulation_credit                float64\n 103  ef_regulation_labor_minwage         float64\n 104  ef_regulation_labor_firing          float64\n 105  ef_regulation_labor_bargain         float64\n 106  ef_regulation_labor_hours           float64\n 107  ef_regulation_labor_dismissal       float64\n 108  ef_regulation_labor_conscription    float64\n 109  ef_regulation_labor                 float64\n 110  ef_regulation_business_adm          float64\n 111  ef_regulation_business_bureaucracy  float64\n 112  ef_regulation_business_start        float64\n 113  ef_regulation_business_bribes       float64\n 114  ef_regulation_business_licensing    float64\n 115  ef_regulation_business_compliance   float64\n 116  ef_regulation_business              float64\n 117  ef_regulation                       float64\n 118  ef_score                            float64\n 119  ef_rank                             float64\n 120  hf_score                            float64\n 121  hf_rank                             float64\n 122  hf_quartile                         float64\ndtypes: float64(119), int64(1), object(3)\nmemory usage: 1.4+ MB\n```\n:::\n:::\n\n\n## `.describe()`\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nhfi.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>pf_rol_procedural</th>\n      <th>pf_rol_civil</th>\n      <th>pf_rol_criminal</th>\n      <th>pf_rol</th>\n      <th>pf_ss_homicide</th>\n      <th>pf_ss_disappearances_disap</th>\n      <th>pf_ss_disappearances_violent</th>\n      <th>pf_ss_disappearances_organized</th>\n      <th>pf_ss_disappearances_fatalities</th>\n      <th>...</th>\n      <th>ef_regulation_business_bribes</th>\n      <th>ef_regulation_business_licensing</th>\n      <th>ef_regulation_business_compliance</th>\n      <th>ef_regulation_business</th>\n      <th>ef_regulation</th>\n      <th>ef_score</th>\n      <th>ef_rank</th>\n      <th>hf_score</th>\n      <th>hf_rank</th>\n      <th>hf_quartile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1458.000000</td>\n      <td>880.000000</td>\n      <td>880.000000</td>\n      <td>880.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n      <td>1369.000000</td>\n      <td>1378.000000</td>\n      <td>1279.000000</td>\n      <td>1378.000000</td>\n      <td>...</td>\n      <td>1283.000000</td>\n      <td>1357.000000</td>\n      <td>1368.000000</td>\n      <td>1374.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n      <td>1378.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2012.000000</td>\n      <td>5.589355</td>\n      <td>5.474770</td>\n      <td>5.044070</td>\n      <td>5.309641</td>\n      <td>7.412980</td>\n      <td>8.341855</td>\n      <td>9.519458</td>\n      <td>6.772869</td>\n      <td>9.584972</td>\n      <td>...</td>\n      <td>4.886192</td>\n      <td>7.698494</td>\n      <td>6.981858</td>\n      <td>6.317668</td>\n      <td>7.019782</td>\n      <td>6.785610</td>\n      <td>76.973149</td>\n      <td>6.993444</td>\n      <td>77.007983</td>\n      <td>2.490566</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.582875</td>\n      <td>2.080957</td>\n      <td>1.428494</td>\n      <td>1.724886</td>\n      <td>1.529310</td>\n      <td>2.832947</td>\n      <td>3.225902</td>\n      <td>1.744673</td>\n      <td>2.768983</td>\n      <td>1.559826</td>\n      <td>...</td>\n      <td>1.889168</td>\n      <td>1.728507</td>\n      <td>1.979200</td>\n      <td>1.230988</td>\n      <td>1.027625</td>\n      <td>0.883601</td>\n      <td>44.540142</td>\n      <td>1.025811</td>\n      <td>44.506549</td>\n      <td>1.119698</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2008.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.009841</td>\n      <td>2.483540</td>\n      <td>2.880000</td>\n      <td>1.000000</td>\n      <td>3.765827</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2010.000000</td>\n      <td>4.133333</td>\n      <td>4.549550</td>\n      <td>3.789724</td>\n      <td>4.131746</td>\n      <td>6.386978</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>5.000000</td>\n      <td>9.942607</td>\n      <td>...</td>\n      <td>3.433786</td>\n      <td>6.874687</td>\n      <td>6.368178</td>\n      <td>5.591851</td>\n      <td>6.429498</td>\n      <td>6.250000</td>\n      <td>38.000000</td>\n      <td>6.336685</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2012.000000</td>\n      <td>5.300000</td>\n      <td>5.300000</td>\n      <td>4.575189</td>\n      <td>4.910797</td>\n      <td>8.638278</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>7.500000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>4.418371</td>\n      <td>8.074161</td>\n      <td>7.466692</td>\n      <td>6.265234</td>\n      <td>7.082075</td>\n      <td>6.900000</td>\n      <td>77.000000</td>\n      <td>6.923840</td>\n      <td>76.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2014.000000</td>\n      <td>7.389499</td>\n      <td>6.410975</td>\n      <td>6.400000</td>\n      <td>6.513178</td>\n      <td>9.454402</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>6.227978</td>\n      <td>8.991882</td>\n      <td>8.209310</td>\n      <td>7.139718</td>\n      <td>7.720955</td>\n      <td>7.410000</td>\n      <td>115.000000</td>\n      <td>7.894660</td>\n      <td>115.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2016.000000</td>\n      <td>9.700000</td>\n      <td>8.773533</td>\n      <td>8.719848</td>\n      <td>8.723094</td>\n      <td>9.926568</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>9.623811</td>\n      <td>9.999638</td>\n      <td>9.865488</td>\n      <td>9.272600</td>\n      <td>9.439828</td>\n      <td>9.190000</td>\n      <td>162.000000</td>\n      <td>9.126313</td>\n      <td>162.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 120 columns</p>\n</div>\n```\n:::\n:::\n\n\n:::\n\n## Identifying missing values {.smaller}\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nhfi.isna().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\nyear                   0\nISO_code               0\ncountries              0\nregion                 0\npf_rol_procedural    578\n                    ... \nef_score              80\nef_rank               80\nhf_score              80\nhf_rank               80\nhf_quartile           80\nLength: 123, dtype: int64\n```\n:::\n:::\n\n\n::: fragment\n> A lot of missing values ðŸ™ƒ\n:::\n\n# Data Cleaning\n\n## Handling missing data\n\n#### Options\n\n::: incremental\n-   Do nothing...\n-   Remove them\n-   **Imputate**\n:::\n\n::: fragment\nWe will be using `pf_score` from `hsi`: 80 missing values\n:::\n\n## Imputation\n\n> In [statistics](https://en.wikipedia.org/wiki/Statistics \"Statistics\"), **imputation** is the process of replacing [missing data](https://en.wikipedia.org/wiki/Missing_data \"Missing data\") with substituted values.\n\n::: fragment\n#### Considerations\n\n::: incremental\n-   Data distribution\n-   Impact on analysis\n-   Missing data mechanism\n-   Multiple imputation\n-   Can also be used on **outliers**\n:::\n:::\n\n## Mean imputation {.smaller}\n\n::: panel-tabset\n## Definition\n\n**How it Works**: Replace missing values with the arithmetic **mean** of the non-missing values in the same variable.\n\n::: fragment\n**Pros**:\n\n::: incremental\n-   Easy and fast.\n-   Works well with small numerical datasets\n:::\n\n**Cons**:\n\n::: incremental\n-   It only works on the column level.\n-   Will give poor results on encoded categorical features.\n-   Not very accurate.\n-   Doesn't account for the uncertainty in the imputations.\n:::\n:::\n\n## Visual\n\n::: {.cell fig.asp='0.625' execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-10-output-1.png){width=824 height=435}\n:::\n:::\n\n\n## Code\n\n::: {.cell execution_count=10}\n``` {.python .cell-code code-line-numbers=\"1-12|1|3,4|6,8,10,12\"}\nhfi_copy = hfi\n\nmean_imputer = SimpleImputer(strategy = 'mean')\nhfi_copy['mean_pf_score'] = mean_imputer.fit_transform(hfi_copy[['pf_score']])\n\nmean_plot = sns.kdeplot(data = hfi_copy, x = 'pf_score', linewidth = 2, label = \"Original\")\n\nmean_plot = sns.kdeplot(data = hfi_copy, x = 'mean_pf_score', linewidth = 2, label = \"Mean Imputated\")\n\nplt.legend()\n\nplt.show()\n```\n:::\n\n\n:::\n\n## Median imputation {.smaller}\n\n::: panel-tabset\n## Definition\n\n**How it Works**: Replace missing values with the **median** of the non-missing values in the same variable.\n\n::: fragment\n**Pros** (same as mean):\n\n::: incremental\n-   Easy and fast.\n-   Works well with small numerical datasets\n:::\n\n**Cons** (same as mean):\n\n::: incremental\n-   It only works on the column level.\n-   Will give poor results on encoded categorical features.\n-   Not very accurate.\n-   Doesn't account for the uncertainty in the imputations.\n:::\n:::\n\n## Visual\n\n::: {.cell fig.asp='0.625' ref.label='mean_imp' execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-12-output-1.png){width=824 height=435}\n:::\n:::\n\n\n## Code\n\n::: {.cell execution_count=12}\n``` {.python .cell-code code-line-numbers=\"1-10|1,2\"}\nmedian_imputer = SimpleImputer(strategy = 'median')\nhfi_copy['median_pf_score'] = median_imputer.fit_transform(hfi_copy[['pf_score']])\n\nmedian_plot = sns.kdeplot(data = hfi_copy, x = 'pf_score', linewidth = 2, label = \"Original\")\n\nmedian_plot = sns.kdeplot(data = hfi_copy, x = 'median_pf_score', linewidth = 2, label = \"Median Imputated\")\n\nplt.legend()\n\nplt.show()\n```\n:::\n\n\n:::\n\n## Mode imputation {.smaller}\n\n::: panel-tabset\n## Definition\n\n**How it Works**: Replace missing values with the **mode** of the non-missing values in the same variable.\n\n::: fragment\n**Pros**:\n\n::: incremental\n-   Easy and fast.\n-   Works well with categorical features.\n:::\n\n**Cons**:\n\n::: incremental\n-   It also doesn't factor the correlations between features.\n-   It can introduce bias in the data.\n:::\n:::\n\n## Visual\n\n::: {.cell fig.asp='0.625' execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-14-output-1.png){width=824 height=435}\n:::\n:::\n\n\n## Code\n\n::: {.cell ref.label='mean-imp' execution_count=14}\n``` {.python .cell-code code-line-numbers=\"1-12|1,2\"}\nmode_imputer = SimpleImputer(strategy = 'most_frequent')\nhfi_copy['mode_pf_score'] = mode_imputer.fit_transform(hfi_copy[['pf_score']])\n\nmode_plot = sns.kdeplot(data = hfi_copy, x = 'pf_score', linewidth = 2, label = \"Original\")\n\nmode_plot = sns.kdeplot(data = hfi_copy, x = 'mode_pf_score', linewidth = 2, label = \"Mode Imputated\")\n\nplt.legend()\n\nplt.show()\n```\n:::\n\n\n:::\n\n## Capping (Winsorizing) imputation {.smaller}\n\n::: panel-tabset\n## Definition\n\n**How it Works**: Replace missing values with the **mode** of the non-missing values in the same variable.\n\n::: fragment\n**Pros**:\n\n::: incremental\n-   Not influenced by extreme values\n:::\n\n**Cons**:\n\n::: incremental\n-   Capping only modifies the smallest and largest values slightly.\n-   If no extreme outliers are present, Winsorization may be unnecessary.\n:::\n:::\n\n## Visual\n\n::: {.cell fig.asp='0.625' execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-16-output-1.png){width=824 height=435}\n:::\n:::\n\n\n## Code\n\n::: {.cell execution_count=16}\n``` {.python .cell-code code-line-numbers=\"1-12|1,2,4\"}\nupper_limit = np.percentile(hfi_copy['pf_score'].dropna(), 95)\nlower_limit = np.percentile(hfi_copy['pf_score'].dropna(), 5)\n\nhfi_copy['capped_pf_score'] = np.clip(hfi_copy['pf_score'], lower_limit, upper_limit)\n\ncap_plot = sns.kdeplot(data = hfi_copy, x = 'pf_score', linewidth = 2, label = \"Original\")\n\ncap_plot = sns.kdeplot(data = hfi_copy, x = 'capped_pf_score', linewidth = 2, label = \"Mode Imputated\")\n\nplt.legend()\n\nplt.show()\n```\n:::\n\n\n:::\n\n## Other Imputation Methods {.smaller}\n\n::: {style=\"text-align: center;\"}\n\n```{=html}\n<iframe width=\"1200\" height=\"400\" src=\"https://datamineaz.org/tables/model-cheatsheet.html\" frameborder=\"1\" style=\"background:white;\"></iframe>\n```\n\n:::\n\n## Data type conversion {.smaller}\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nhfi['year'] = pd.to_datetime(hfi['year'], format='%Y')\n\nhfi.head(1)\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>ISO_code</th>\n      <th>countries</th>\n      <th>region</th>\n      <th>pf_rol_procedural</th>\n      <th>pf_rol_civil</th>\n      <th>pf_rol_criminal</th>\n      <th>pf_rol</th>\n      <th>pf_ss_homicide</th>\n      <th>pf_ss_disappearances_disap</th>\n      <th>...</th>\n      <th>ef_regulation</th>\n      <th>ef_score</th>\n      <th>ef_rank</th>\n      <th>hf_score</th>\n      <th>hf_rank</th>\n      <th>hf_quartile</th>\n      <th>mean_pf_score</th>\n      <th>median_pf_score</th>\n      <th>mode_pf_score</th>\n      <th>capped_pf_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-01</td>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>Eastern Europe</td>\n      <td>6.661503</td>\n      <td>4.547244</td>\n      <td>4.666508</td>\n      <td>5.291752</td>\n      <td>8.920429</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>6.906901</td>\n      <td>7.54</td>\n      <td>34.0</td>\n      <td>7.56814</td>\n      <td>48.0</td>\n      <td>2.0</td>\n      <td>7.596281</td>\n      <td>7.596281</td>\n      <td>7.596281</td>\n      <td>7.596281</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 127 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nhfi.dtypes\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```\nyear                 datetime64[ns]\nISO_code                     object\ncountries                    object\nregion                       object\npf_rol_procedural           float64\n                          ...      \nhf_quartile                 float64\nmean_pf_score               float64\nmedian_pf_score             float64\nmode_pf_score               float64\ncapped_pf_score             float64\nLength: 127, dtype: object\n```\n:::\n:::\n\n\n## Removing duplicates {.smaller}\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nhfi.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1458 entries, 0 to 1457\nColumns: 127 entries, year to capped_pf_score\ndtypes: datetime64[ns](1), float64(123), object(3)\nmemory usage: 1.4+ MB\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nhfi.drop_duplicates(inplace = True)\nhfi.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1458 entries, 0 to 1457\nColumns: 127 entries, year to capped_pf_score\ndtypes: datetime64[ns](1), float64(123), object(3)\nmemory usage: 1.4+ MB\n```\n:::\n:::\n\n\n::: fragment\n> No duplicates! ðŸ˜Š\n:::\n\n## Filtering data {.smaller}\n\n::: panel-tabset\n## Category\n\nLet's look at USA, India, Canada, China\n\n::: {.cell execution_count=21}\n``` {.python .cell-code code-line-numbers=\"1-6|1|2|5,6\"}\noptions = ['United States', 'India', 'Canada', 'China']\n\nfiltered_hfi = hfi[hfi['countries'].isin(options)]\n\nunique_countries = filtered_hfi['countries'].unique()\nprint(unique_countries)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Canada' 'China' 'India' 'United States']\n```\n:::\n:::\n\n\n## Numeric\n\nLet's look at [Economic Freedom](https://www.investopedia.com/terms/i/index-of-economic-freedom.asp#:~:text=An%20index%20of%20economic%20freedom%20is%20a%20composite,criteria%20such%20as%20property%20rights%20and%20tax%20burden.) \\> 75\n\n::: {.cell execution_count=22}\n``` {.python .cell-code code-line-numbers=\"1-3|1\"}\nfiltered_hfi = hfi[hfi['pf_score'] > 8]\nsns.boxplot(filtered_hfi, x = \"pf_score\", y = \"countries\", palette = \"colorblind\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-23-output-1.png){width=956 height=437}\n:::\n:::\n\n\n:::\n\n# Transformations\n\n## Normalizing {.smaller}\n\n::: panel-tabset\n## Standard Deviation\n\n::: {.cell execution_count=23}\n\n::: {.cell-output .cell-output-stdout}\n```\nMean: 5\nStandard Deviation: 2\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-24-output-2.png){width=832 height=442}\n:::\n:::\n\n\n## Z-Score Normalization\n\n::: {.cell execution_count=24}\n``` {.python .cell-code code-line-numbers=\"1-6|3,4|5\"}\nhfi_copy = hfi\n\nscaler = StandardScaler()\nhfi_copy[['ef_score_scale', 'ef_score_scale']] = scaler.fit_transform(hfi_copy[['ef_score', 'pf_score']])\n\nhfi_copy[['ef_score_scale', 'ef_score_scale']].describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ef_score_scale</th>\n      <th>ef_score_scale</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.378000e+03</td>\n      <td>1.378000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.062533e-17</td>\n      <td>2.062533e-17</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.000363e+00</td>\n      <td>1.000363e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.663087e+00</td>\n      <td>-3.663087e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-7.303950e-01</td>\n      <td>-7.303950e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-8.926277e-03</td>\n      <td>-8.926277e-03</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9.081441e-01</td>\n      <td>9.081441e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.722056e+00</td>\n      <td>1.722056e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n:::\n\n## Normality test: Q-Q plot {.smaller}\n\n::: panel-tabset\n## Q-Q Plot\n\n::: {.cell execution_count=25}\n``` {.python .cell-code code-fold=\"true\"}\nhfi_clean = hfi_copy.dropna(subset = ['pf_score'])\n\nsns.set_style(\"white\")\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(data = hfi_clean, x = \"pf_score\", linewidth = 5, ax = ax1)\nax1.set_title('Personal Freedom Score')\n\nsm.qqplot(hfi_clean['pf_score'], line = 's', ax = ax2, dist = stats.norm, fit = True)\nax2.set_title('Personal Freedom Score Q-Q plot')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-26-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## Issues\n\n**There were some issues in our plots**:\n\n::: incremental\n-   **Left Tail**: Points deviate downwards from the line, indicating more extreme low values than a normal distribution (**negative skewness**).\n\n-   **Central Section**: Points align closely with the line, suggesting the central data is *similar to a normal distribution*.\n\n-   **Right Tail**: Points curve upwards, showing potential for **extreme high values (positive skewness)**.\n:::\n:::\n\n## Correcting skew {.smaller}\n\n::: fragment\n[Square-root transformation](https://en.wikipedia.org/wiki/Square_root). $\\sqrt x$ Used for **moderately** right-skew **(positive skew)**\n\n::: incremental\n-   Cannot handle negative values (but can handle zeros)\n:::\n:::\n\n::: fragment\n[Log transformation](https://en.wikipedia.org/wiki/Logarithm). $log(x + 1)$ Used for **substantial** right-skew **(positive skew)**\n\n::: incremental\n-   Cannot handle negative or zero values\n:::\n:::\n\n::: fragment\n[Inverse transformation](https://en.wikipedia.org/wiki/Inverse_function). $\\frac{1}{x}$ Used for **severe** right-skew **(positive skew)**\n\n::: incremental\n-   Cannot handle negative or zero values\n:::\n:::\n\n::: fragment\n[Squared transformation](https://en.wikipedia.org/wiki/Quadratic_function). $x^2$ Used for **moderately** left-skew **(negative skew)**\n\n::: incremental\n-   Effective when lower values are densely packed together\n:::\n:::\n\n::: fragment\n[Cubed transformation](https://en.wikipedia.org/wiki/Cubic_function). $x^3$ Used for **severely** left-skew **(negative skew)**\n\n::: incremental\n-   Further stretches the tail of the distribution\n:::\n:::\n\n## Comparing transformations {.smaller}\n\n::: panel-tabset\n## Original\n\n::: {.cell execution_count=26}\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-27-output-1.png){width=937 height=454}\n:::\n:::\n\n\n::: fragment\n**Moderate negative skew, no zeros or negative values**\n:::\n\n## Square-root\n\n::: {.cell execution_count=27}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-13|1|2,7,10\"}\nhfi_clean['pf_score_sqrt'] = np.sqrt(hfi_clean['pf_score'])\n\ncol = hfi_clean['pf_score_sqrt']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Square-root Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Square-root Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-28-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## Log\n\n::: {.cell execution_count=28}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-13|1\"}\nhfi_clean['pf_score_log'] = np.log(hfi_clean['pf_score'] + 1)\n\ncol = hfi_clean['pf_score_log']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Log Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Log Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-29-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## Inverse\n\n::: {.cell execution_count=29}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-13|1\"}\nhfi_clean['pf_score_inv'] = 1/hfi_clean.pf_score\n\ncol = hfi_clean['pf_score_inv']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Inverse Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Inverse Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-30-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## Squared\n\n::: {.cell execution_count=30}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-13|1\"}\nhfi_clean['pf_score_square'] = pow(hfi_clean.pf_score, 2)\n\ncol = hfi_clean['pf_score_square']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Squared Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Squared Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-31-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## Cubed\n\n::: {.cell execution_count=31}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-13|1\"}\nhfi_clean['pf_score_cube'] = pow(hfi_clean.pf_score, 3)\n\ncol = hfi_clean['pf_score_cube']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Cubed Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Cubed Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-32-output-1.png){width=937 height=454}\n:::\n:::\n\n\n:::\n\n## What did we learn?\n\n::: incremental\n-   Negative skew excluded all but **Squared** and **Cubed** transformations\n\n-   **Squared** transformation was the best\n\n-   The data is **bimodal**, so no transformation is perfect\n:::\n\n## Aside: dealing with multimodality\n\n::: incremental\n-   K-Means Clustering\n\n    -   We will learn this later\n\n-   Gaussian Mixture Models\n\n    -   Also later\n\n-   Thresholding\n\n    -   No obvious valley\n\n-   Domain knowledge\n\n    -   None that is applicable\n\n-   [**Kernel Density Estimation (KDE)**](https://en.wikipedia.org/wiki/Kernel_density_estimation)\n:::\n\n## Kernel Density Estimation (KDE) {.smaller}\n\n**Finding valleys in multimodal data, then splitting**\n\n$$\\hat{f}(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x - x_i}{h}\\right)$$\n\n::: incremental\n-   $\\hat{f}(x)$ is the estimated probability density function at point $x$.\n\n-   $n$ is the number of data points.\n\n-   $x_i$ are the observed data points.\n\n-   $h$ is the bandwidth.\n\n-   $K$ is the kernel function, which is a non-negative function that integrates to one and is symmetric around zero.\n:::\n\n::: fragment\nThe choice of $h$ and $K$ can significantly affect the resulting estimate.\n:::\n\n::: fragment\nCommon choices for the kernel function $K$ include the [**Gaussian kernel**](https://en.wikipedia.org/wiki/Kernel_smoother#Gaussian_kernel_smoother) and [Epanechnikov kernel](https://www.gabormelli.com/RKB/Epanechnikov_Kernel#:~:text=An%20Epanechnikov%20Kernel%20is%20a%20kernel%20function%20that,be%20optimal%20with%20respect%20to%20Mean%20Square%20Error.)\n:::\n\n## KDE: bandwidth method {.smaller}\n\n**In density estimations, there is a smoothing parameter**\n\n::: fragment\n**Scott's Rule**\n\n::: incremental\n-   Rule of thumb for choosing kernal bandwidth\n-   Proportional to the standard deviation of the data and inversely proportional to the cube root of the sample size (n).\n-   Formula: $h = \\sigma \\cdot n^{-\\frac{1}{3}}$\n-   Tends to produce a smoother density estimation\n-   Suitable for data that is roughly normally distributed\n:::\n:::\n\n::: fragment\n**Silverman's Rule**\n\n::: incremental\n-   Another popular rule of thumb\n-   Similar to Scott's rule but potentially leading to a smaller bandwidth.\n-   Formula: $h = \\left( \\frac{4\\hat{\\sigma}^5}{3n} \\right)^{\\frac{1}{5}}$\n-   Can be better for data with outliers or heavy tails\n:::\n:::\n\n## KDE: our data {.smaller}\n\n::: {.cell execution_count=32}\n``` {.python .cell-code code-fold=\"true\" code-line-numbers=\"1-16|1-4|6,7|12|16\"}\nvalues = hfi_clean['pf_score_square']\nkde = gaussian_kde(values, bw_method = 'scott')\nx_eval = np.linspace(values.min(), values.max(), num = 500) \nkde_values = kde(x_eval)\n\nminima_indices = argrelextrema(kde_values, np.less)[0]\nvalleys = x_eval[minima_indices]\n\nplt.figure(figsize = (7, 5))\nplt.title('KDE and Valleys')\nsns.lineplot(x = x_eval, y = kde_values, label = 'KDE')\nplt.scatter(x = valleys, y = kde(valleys), color = 'r', zorder = 5, label = 'Valleys')\nplt.legend()\nplt.show()\n\nprint(\"Valley x-values:\", valleys)\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-33-output-1.png){width=605 height=438}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nValley x-values: [68.39968248]\n```\n:::\n:::\n\n\n## Split the data {.smaller}\n\n::: {.cell execution_count=33}\n``` {.python .cell-code code-line-numbers=\"1-5|1,2|4\"}\nvalley = 68.39968248\nhfi_clean['group'] = np.where(hfi_clean['pf_score_square'] < valley, 'group1', 'group2')\n\ndata = hfi_clean[['group', 'pf_score_square']].sort_values(by = 'pf_score_square')\ndata.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=73}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>pf_score_square</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>159</th>\n      <td>group1</td>\n      <td>4.693962</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>group1</td>\n      <td>5.461029</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>group1</td>\n      <td>6.308405</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>group1</td>\n      <td>6.345709</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>group1</td>\n      <td>8.189057</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\ndata.tail()\n```\n\n::: {.cell-output .cell-output-display execution_count=74}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>pf_score_square</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>435</th>\n      <td>group2</td>\n      <td>90.755418</td>\n    </tr>\n    <tr>\n      <th>1407</th>\n      <td>group2</td>\n      <td>91.284351</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>group2</td>\n      <td>91.396839</td>\n    </tr>\n    <tr>\n      <th>1083</th>\n      <td>group2</td>\n      <td>91.428990</td>\n    </tr>\n    <tr>\n      <th>759</th>\n      <td>group2</td>\n      <td>91.549575</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Plot the grouped data\n\n::: {.cell execution_count=35}\n``` {.python .cell-code code-fold=\"true\"}\nsns.histplot(data = hfi_clean, x = \"pf_score_square\", \n            hue = \"group\", kde = True, stat = \"density\", common_norm = False)\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-36-output-1.png){width=831 height=439}\n:::\n:::\n\n\n# Back to our question\n\n## Question\n\nHow does **environmental stability** [correlate]{.underline} with **human freedom indices** in [different countries]{.underline}, and what [trends]{.underline} can be observed over [recent years]{.underline}?\n\n::: fragment\n::: incremental\n-   We can use the **`pf_score`** from the `hfi` dataset that we've been using.\n\n-   ...but we need an environmental stability index score.\n:::\n:::\n\n## Dataset #2: Environmental Stability {.smaller}\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nesi = pd.read_csv(\"data/esi.csv\")\nesi.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=76}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>country</th>\n      <th>esi</th>\n      <th>system</th>\n      <th>stress</th>\n      <th>vulner</th>\n      <th>cap</th>\n      <th>global</th>\n      <th>sys_air</th>\n      <th>sys_bio</th>\n      <th>...</th>\n      <th>vul_hea</th>\n      <th>vul_sus</th>\n      <th>vul_dis</th>\n      <th>cap_gov</th>\n      <th>cap_eff</th>\n      <th>cap_pri</th>\n      <th>cap_st</th>\n      <th>glo_col</th>\n      <th>glo_ghg</th>\n      <th>glo_tbp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>58.8</td>\n      <td>52.4</td>\n      <td>65.4</td>\n      <td>72.3</td>\n      <td>46.2</td>\n      <td>57.9</td>\n      <td>0.45</td>\n      <td>0.17</td>\n      <td>...</td>\n      <td>0.32</td>\n      <td>0.79</td>\n      <td>0.66</td>\n      <td>-0.32</td>\n      <td>0.79</td>\n      <td>-0.65</td>\n      <td>-0.20</td>\n      <td>-0.45</td>\n      <td>0.21</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DZA</td>\n      <td>Algeria</td>\n      <td>46.0</td>\n      <td>43.1</td>\n      <td>66.3</td>\n      <td>57.5</td>\n      <td>31.8</td>\n      <td>21.1</td>\n      <td>-0.02</td>\n      <td>-0.08</td>\n      <td>...</td>\n      <td>-0.33</td>\n      <td>0.45</td>\n      <td>0.45</td>\n      <td>-0.69</td>\n      <td>-0.28</td>\n      <td>-0.66</td>\n      <td>-0.27</td>\n      <td>-0.51</td>\n      <td>-0.56</td>\n      <td>-1.33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGO</td>\n      <td>Angola</td>\n      <td>42.9</td>\n      <td>67.9</td>\n      <td>59.1</td>\n      <td>11.8</td>\n      <td>22.1</td>\n      <td>39.1</td>\n      <td>-0.77</td>\n      <td>0.77</td>\n      <td>...</td>\n      <td>-1.75</td>\n      <td>-1.91</td>\n      <td>0.11</td>\n      <td>-0.96</td>\n      <td>0.12</td>\n      <td>-1.08</td>\n      <td>-1.16</td>\n      <td>-0.88</td>\n      <td>0.31</td>\n      <td>-0.26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ARG</td>\n      <td>Argentina</td>\n      <td>62.7</td>\n      <td>67.6</td>\n      <td>54.9</td>\n      <td>69.9</td>\n      <td>65.4</td>\n      <td>58.5</td>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>...</td>\n      <td>0.85</td>\n      <td>0.69</td>\n      <td>0.03</td>\n      <td>-0.34</td>\n      <td>0.18</td>\n      <td>1.23</td>\n      <td>0.51</td>\n      <td>0.45</td>\n      <td>0.09</td>\n      <td>0.11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ARM</td>\n      <td>Armenia</td>\n      <td>53.2</td>\n      <td>54.4</td>\n      <td>62.2</td>\n      <td>50.8</td>\n      <td>34.9</td>\n      <td>60.3</td>\n      <td>1.21</td>\n      <td>-0.02</td>\n      <td>...</td>\n      <td>0.29</td>\n      <td>-0.79</td>\n      <td>0.56</td>\n      <td>-0.38</td>\n      <td>-0.66</td>\n      <td>-0.55</td>\n      <td>0.03</td>\n      <td>-0.29</td>\n      <td>-0.29</td>\n      <td>1.37</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: fragment\n::: incremental\n-   Looks like the `esi` column will work!\n\n-   But there's a problem...\n\n-   We only have one year in this dataset\n\n-   P.S. there's no missing values\n:::\n:::\n\n## Grouping and aggregating {.smaller}\n\n::: {.cell execution_count=37}\n``` {.python .cell-code code-line-numbers=\"1-4|1-2|3\"}\ngrouped_hfi = hfi.groupby('countries').agg({'region': 'first', \n                                            'pf_score': 'mean'\n                                           }).reset_index()\ngrouped_hfi.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=77}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>countries</th>\n      <th>region</th>\n      <th>pf_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albania</td>\n      <td>Eastern Europe</td>\n      <td>7.696934</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Algeria</td>\n      <td>Middle East &amp; North Africa</td>\n      <td>5.249383</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Angola</td>\n      <td>Sub-Saharan Africa</td>\n      <td>5.856932</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Argentina</td>\n      <td>Latin America &amp; the Caribbean</td>\n      <td>8.120779</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Armenia</td>\n      <td>Caucasus &amp; Central Asia</td>\n      <td>7.192095</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Joining the data {.smaller}\n\n::: {.cell execution_count=38}\n``` {.python .cell-code code-line-numbers=\"1-5|1-2|4\"}\ngrouped_hfi['country'] = grouped_hfi['countries']\nmerged_data = esi.merge(grouped_hfi, how = 'left', on = 'country')\n\nesi_hfi = merged_data[['esi', 'pf_score', 'region', 'country']]\nesi_hfi.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=78}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>esi</th>\n      <th>pf_score</th>\n      <th>region</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58.8</td>\n      <td>7.696934</td>\n      <td>Eastern Europe</td>\n      <td>Albania</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46.0</td>\n      <td>5.249383</td>\n      <td>Middle East &amp; North Africa</td>\n      <td>Algeria</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42.9</td>\n      <td>5.856932</td>\n      <td>Sub-Saharan Africa</td>\n      <td>Angola</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62.7</td>\n      <td>8.120779</td>\n      <td>Latin America &amp; the Caribbean</td>\n      <td>Argentina</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53.2</td>\n      <td>7.192095</td>\n      <td>Caucasus &amp; Central Asia</td>\n      <td>Armenia</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: incremental\n-   ...but what's the new problem?\n\n-   We need to **standardize** the data.\n\n-   Lucky for us this will also help control outliers!\n:::\n\n## Back to missing values\n\nWe are going to drop them, since they are also present in `region`\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nesi_hfi_red = esi_hfi.dropna()\nesi_hfi_red.isna().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n```\nesi         0\npf_score    0\nregion      0\ncountry     0\ndtype: int64\n```\n:::\n:::\n\n\n# Transformations\n\n## Normality test: Q-Q plot {.smaller}\n\n::: panel-tabset\n## `pf_score`\n\n::: {.cell execution_count=40}\n``` {.python .cell-code code-fold=\"true\"}\nsns.set_style(\"white\")\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(data = esi_hfi_red, x = \"pf_score\", linewidth = 5, ax = ax1)\nax1.set_title('Personal Freedom Score')\n\nsm.qqplot(esi_hfi_red['pf_score'], line = 's', ax = ax2, dist = stats.norm, fit = True)\nax2.set_title('Personal Freedom Score Q-Q plot')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-41-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## `esi`\n\n::: {.cell execution_count=41}\n``` {.python .cell-code code-fold=\"true\"}\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(data = esi_hfi_red, x = \"esi\", linewidth = 5, ax = ax1)\nax1.set_title('Environmental Stability Score')\n\nsm.qqplot(esi_hfi_red['esi'], line = 's', ax = ax2, dist = stats.norm, fit = True)\nax2.set_title('Environmental Stability Score Q-Q plot')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-42-output-1.png){width=937 height=455}\n:::\n:::\n\n\n:::\n\n## Correcting skew {.smaller}\n\n::: panel-tabset\n## `pf_score`\n\n::: {.cell execution_count=42}\n``` {.python .cell-code code-fold=\"true\"}\nesi_hfi_red['pf_score_square'] = pow(esi_hfi_red.pf_score, 2)\n\ncol = esi_hfi_red['pf_score_square']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Squared Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Squared Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-43-output-1.png){width=937 height=454}\n:::\n:::\n\n\n## `esi`\n\n::: {.cell execution_count=43}\n``` {.python .cell-code code-fold=\"true\"}\nesi_hfi_red['esi_log'] = np.log(esi_hfi_red.esi + 1)\n\ncol = esi_hfi_red['esi_log']\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2, nrows = 1)\n\nsns.kdeplot(col, linewidth = 5, ax = ax1)\nax1.set_title('Log Density plot')    \n\nsm.qqplot(col, line = 's', ax = ax2)\nax2.set_title('Log Q-Q plot')    \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-44-output-1.png){width=937 height=454}\n:::\n:::\n\n\n:::\n\n## Normalizing {.smaller}\n\n::: {.cell execution_count=44}\n``` {.python .cell-code}\nscaler = StandardScaler()\nesi_hfi_red[['esi_log', 'pf_score_square']] = scaler.fit_transform(esi_hfi_red[['esi_log', 'pf_score_square']])\n\nesi_hfi_red.describe().round(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=84}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>esi</th>\n      <th>pf_score</th>\n      <th>pf_score_square</th>\n      <th>esi_log</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>129.000</td>\n      <td>129.000</td>\n      <td>129.000</td>\n      <td>129.000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>50.599</td>\n      <td>7.114</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.304</td>\n      <td>1.407</td>\n      <td>1.004</td>\n      <td>1.004</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>32.700</td>\n      <td>3.116</td>\n      <td>-2.158</td>\n      <td>-2.604</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>44.800</td>\n      <td>6.141</td>\n      <td>-0.748</td>\n      <td>-0.671</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>50.000</td>\n      <td>7.029</td>\n      <td>-0.159</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>56.100</td>\n      <td>8.415</td>\n      <td>0.919</td>\n      <td>0.718</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>75.100</td>\n      <td>9.476</td>\n      <td>1.875</td>\n      <td>2.527</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Correlations {.smaller}\n\n::: panel-tabset\n## Correlation\n\n::: {.cell execution_count=45}\n``` {.python .cell-code}\nesi_hfi_num = esi_hfi_red.select_dtypes(include = 'number')\n\ncorr = esi_hfi_num.corr()\ncorr\n```\n\n::: {.cell-output .cell-output-display execution_count=85}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>esi</th>\n      <th>pf_score</th>\n      <th>pf_score_square</th>\n      <th>esi_log</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>esi</th>\n      <td>1.000000</td>\n      <td>0.612156</td>\n      <td>0.613844</td>\n      <td>0.993689</td>\n    </tr>\n    <tr>\n      <th>pf_score</th>\n      <td>0.612156</td>\n      <td>1.000000</td>\n      <td>0.993128</td>\n      <td>0.610484</td>\n    </tr>\n    <tr>\n      <th>pf_score_square</th>\n      <td>0.613844</td>\n      <td>0.993128</td>\n      <td>1.000000</td>\n      <td>0.605737</td>\n    </tr>\n    <tr>\n      <th>esi_log</th>\n      <td>0.993689</td>\n      <td>0.610484</td>\n      <td>0.605737</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Plot\n\n::: {.cell execution_count=46}\n``` {.python .cell-code code-fold=\"true\"}\nplt.figure(figsize = (7, 5))\nax = sns.scatterplot(data = esi_hfi_red, x = \"pf_score_square\", y = \"esi_log\",\n                hue = \"region\", palette = \"colorblind\")\nax.legend(title = \"Region\",\n          bbox_to_anchor = (1.02, 1), loc = 'upper left', borderaxespad = 0)\nax.set(xlabel = \"Personal Freedom Log-Normal \")\nax.set(ylabel = \"Environmental Stability Squared-Normal\")\nax.set(title = \"Human Freedom Index vs. Environmental Stability\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-47-output-1.png){width=906 height=460}\n:::\n:::\n\n\n:::\n\n## Correlations: p-value {.smaller}\n\n::: panel-tabset\n## p-value\n\n::: {.cell execution_count=47}\n``` {.python .cell-code}\nx = esi_hfi_red['pf_score_square']\ny = esi_hfi_red['esi_log']\ncorr_coefficient, p_value = pearsonr(x, y)\n\nprint(\"Pearson correlation coefficient:\", corr_coefficient.round(3))\nprint(\"P-value:\", p_value.round(5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPearson correlation coefficient: 0.606\nP-value: 0.0\n```\n:::\n:::\n\n\n## Trend line\n\n::: {.cell execution_count=48}\n``` {.python .cell-code code-fold=\"true\"}\nsns.lmplot(data = esi_hfi_red, x = \"pf_score_square\", y = \"esi_log\", height = 5, aspect = 7/5)\n\nplt.xlabel(\"Personal Freedom Log-Normal\")\nplt.ylabel(\"Environmental Stability Squared-Normal\")\nplt.title(\"Human Freedom Index vs. Environmental Stability\")\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](04-preprocess_files/figure-revealjs/cell-49-output-1.png){width=648 height=476}\n:::\n:::\n\n\n:::\n\n## Conclusions: question\n\nHow does **environmental stability** [correlate]{.underline} with **human freedom indices** in [different countries]{.underline}, and what [trends]{.underline} can be observed over [recent years]{.underline}?\n\n::: incremental\n1.  We can't make inferences about [recent years]{.underline}...\n2.  **Moderate positive correlation** between **human freedom index** and **environmental stability**\n3.  We cannot find a relationship between countries either\n4.  We need a **linear regression** next ([later]{.underline})\n:::\n\n## Conclusions: data preprocessing\n\n**There are multiple steps:**\n\n::: incremental\n1.  Check the **distribution** for **normality**\n\n2.  Likely will need a **transformation** based on the **severity** and **direction of skew**\n\n3.  **Normalize** the data with different units\n\n4.  **Correlations** are a good start, but **regressions** are more definitive\n:::\n\n",
    "supporting": [
      "04-preprocess_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}